{"config":{"indexing":"full","lang":["en"],"min_search_length":2,"prebuild_index":false,"separator":"[\\s\\-\\.]+"},"docs":[{"location":"","text":"Hey there! \ud83d\udc4b \u00b6 I'm a DevOps enthusiast who loves tinkering with cloud infrastructure and automation. Currently working as a Site Reliability Engineer, I spend my days crafting CI/CD pipelines, managing Kubernetes clusters, and making sure systems run smoothly. What I Do \u00b6 When I'm not debugging production issues or optimizing deployments, you'll find me: Experimenting with new tools in my home lab Contributing to open-source projects Writing about my tech adventures and learnings Breaking (and fixing!) things in my test environment Tech Stack \u00b6 I work with a variety of tools and technologies: Container Orchestration : Kubernetes, Docker Infrastructure as Code : Terraform, Ansible Cloud Platforms : AWS, GCP CI/CD : Jenkins, GitHub Actions Monitoring : Prometheus, Grafana Scripting : Python, Bash Current Focus \u00b6 These days, I'm particularly interested in: GitOps practices and tools Cloud-native security Infrastructure automation Performance optimization Beyond Tech \u00b6 When I'm not immersed in DevOps, I enjoy: \ud83c\udfc3\u200d\u2642\ufe0f Trail running \ud83d\udcda Reading tech blogs and sci-fi \ud83c\udfb8 Playing guitar \ud83c\udf31 Contributing to tech communities Let's Connect \u00b6 Feel free to reach out if you want to: Chat about DevOps and SRE Collaborate on projects Share knowledge and experiences Just say hi! You can find my contact details in the Contact section, or check out my technical documentation under Documentation. Homepage: https://darkmode.dev","title":"Welcome"},{"location":"#hey-there","text":"I'm a DevOps enthusiast who loves tinkering with cloud infrastructure and automation. Currently working as a Site Reliability Engineer, I spend my days crafting CI/CD pipelines, managing Kubernetes clusters, and making sure systems run smoothly.","title":"Hey there! \ud83d\udc4b"},{"location":"#what-i-do","text":"When I'm not debugging production issues or optimizing deployments, you'll find me: Experimenting with new tools in my home lab Contributing to open-source projects Writing about my tech adventures and learnings Breaking (and fixing!) things in my test environment","title":"What I Do"},{"location":"#tech-stack","text":"I work with a variety of tools and technologies: Container Orchestration : Kubernetes, Docker Infrastructure as Code : Terraform, Ansible Cloud Platforms : AWS, GCP CI/CD : Jenkins, GitHub Actions Monitoring : Prometheus, Grafana Scripting : Python, Bash","title":"Tech Stack"},{"location":"#current-focus","text":"These days, I'm particularly interested in: GitOps practices and tools Cloud-native security Infrastructure automation Performance optimization","title":"Current Focus"},{"location":"#beyond-tech","text":"When I'm not immersed in DevOps, I enjoy: \ud83c\udfc3\u200d\u2642\ufe0f Trail running \ud83d\udcda Reading tech blogs and sci-fi \ud83c\udfb8 Playing guitar \ud83c\udf31 Contributing to tech communities","title":"Beyond Tech"},{"location":"#lets-connect","text":"Feel free to reach out if you want to: Chat about DevOps and SRE Collaborate on projects Share knowledge and experiences Just say hi! You can find my contact details in the Contact section, or check out my technical documentation under Documentation. Homepage: https://darkmode.dev","title":"Let's Connect"},{"location":"about/","text":"About Me \u00b6 Welcome to My DevOps Documentation \u00b6 I'm a DevOps enthusiast passionate about automation, infrastructure as code, and continuous integration/deployment practices. This documentation site serves as both a personal knowledge base and a resource for others in the DevOps community. What I Do \u00b6 Infrastructure Automation : Expertise in tools like Terraform, Ansible, and CloudFormation Container Orchestration : Working with Docker and Kubernetes CI/CD Implementation : Setting up and optimizing deployment pipelines Cloud Architecture : Experience with major cloud providers (AWS, GCP, Azure) Purpose of This Site \u00b6 This documentation site aims to: Share knowledge and best practices in DevOps Provide practical guides and tutorials Document common solutions to technical challenges Create a reliable reference for DevOps tools and practices Skills & Expertise \u00b6 Languages : Python, Bash, Go Infrastructure : Docker, Kubernetes, Terraform CI/CD : Jenkins, GitHub Actions, GitLab CI Monitoring : Prometheus, Grafana Cloud Platforms : AWS, GCP, Azure Get in Touch \u00b6 Feel free to reach out if you: - Have questions about any of the documentation - Want to contribute to the content - Need consulting or professional advice - Just want to connect and discuss DevOps You can find me on GitHub or through the contact page.","title":"About Me"},{"location":"about/#about-me","text":"","title":"About Me"},{"location":"about/#welcome-to-my-devops-documentation","text":"I'm a DevOps enthusiast passionate about automation, infrastructure as code, and continuous integration/deployment practices. This documentation site serves as both a personal knowledge base and a resource for others in the DevOps community.","title":"Welcome to My DevOps Documentation"},{"location":"about/#what-i-do","text":"Infrastructure Automation : Expertise in tools like Terraform, Ansible, and CloudFormation Container Orchestration : Working with Docker and Kubernetes CI/CD Implementation : Setting up and optimizing deployment pipelines Cloud Architecture : Experience with major cloud providers (AWS, GCP, Azure)","title":"What I Do"},{"location":"about/#purpose-of-this-site","text":"This documentation site aims to: Share knowledge and best practices in DevOps Provide practical guides and tutorials Document common solutions to technical challenges Create a reliable reference for DevOps tools and practices","title":"Purpose of This Site"},{"location":"about/#skills-expertise","text":"Languages : Python, Bash, Go Infrastructure : Docker, Kubernetes, Terraform CI/CD : Jenkins, GitHub Actions, GitLab CI Monitoring : Prometheus, Grafana Cloud Platforms : AWS, GCP, Azure","title":"Skills &amp; Expertise"},{"location":"about/#get-in-touch","text":"Feel free to reach out if you: - Have questions about any of the documentation - Want to contribute to the content - Need consulting or professional advice - Just want to connect and discuss DevOps You can find me on GitHub or through the contact page.","title":"Get in Touch"},{"location":"contact/","text":"Get in Touch \u00b6 Connect With Me \u00b6 I'm always interested in connecting with fellow DevOps practitioners, developers, and technology enthusiasts. Feel free to reach out through any of the following channels: Social Media \u00b6 GitHub : github.com/depgod Twitter : @myuser LinkedIn : LinkedIn Profile Professional Inquiries \u00b6 For professional inquiries regarding: - Consulting opportunities - Technical collaboration - Speaking engagements - Training sessions Please reach out via email or connect on LinkedIn. Contributing \u00b6 Interested in contributing to this documentation? Here's how you can help: Submit Issues : Found a mistake or have a suggestion? Open an issue on GitHub. Pull Requests : Want to contribute directly? Submit a pull request with your changes. Feedback : Share your thoughts on the documentation structure and content. Community \u00b6 Join our community discussions: - GitHub Discussions - Technical Forums - DevOps Communities Response Time \u00b6 I typically respond to inquiries within 24-48 hours. For urgent matters, please indicate so in your message. Looking forward to connecting with you!","title":"Get in Touch"},{"location":"contact/#get-in-touch","text":"","title":"Get in Touch"},{"location":"contact/#connect-with-me","text":"I'm always interested in connecting with fellow DevOps practitioners, developers, and technology enthusiasts. Feel free to reach out through any of the following channels:","title":"Connect With Me"},{"location":"contact/#social-media","text":"GitHub : github.com/depgod Twitter : @myuser LinkedIn : LinkedIn Profile","title":"Social Media"},{"location":"contact/#professional-inquiries","text":"For professional inquiries regarding: - Consulting opportunities - Technical collaboration - Speaking engagements - Training sessions Please reach out via email or connect on LinkedIn.","title":"Professional Inquiries"},{"location":"contact/#contributing","text":"Interested in contributing to this documentation? Here's how you can help: Submit Issues : Found a mistake or have a suggestion? Open an issue on GitHub. Pull Requests : Want to contribute directly? Submit a pull request with your changes. Feedback : Share your thoughts on the documentation structure and content.","title":"Contributing"},{"location":"contact/#community","text":"Join our community discussions: - GitHub Discussions - Technical Forums - DevOps Communities","title":"Community"},{"location":"contact/#response-time","text":"I typically respond to inquiries within 24-48 hours. For urgent matters, please indicate so in your message. Looking forward to connecting with you!","title":"Response Time"},{"location":"k3s-ha-cluster/","text":"High Availability K3s Cluster Setup Guide \u00b6 Overview \u00b6 Guide Information Difficulty : Advanced Time Required : ~1 hour Last Updated : March 2024 K3s Version : v1.29.1+k3s2 Longhorn Version : v1.6.0 Architecture Overview \u00b6 graph TD subgraph \"Control Plane\" A[Master Node<br/>etcd + K3s Server] end subgraph \"Worker Nodes\" B[Worker Node 1<br/>K3s Agent] C[Worker Node 2<br/>K3s Agent] D[Worker Node 3<br/>K3s Agent] end subgraph \"Storage Layer\" E[Longhorn<br/>Distributed Block Storage] end A --> B A --> C A --> D B --> E C --> E D --> E style A fill:#f9f,stroke:#333 style E fill:#bbf,stroke:#333 Prerequisites \u00b6 System Requirements Master Node Worker Nodes Network Requirements 2 CPU cores 4GB RAM 40GB disk space Ubuntu 22.04 LTS Static IP address 2 CPU cores 8GB RAM 100GB disk space Ubuntu 22.04 LTS Static IP addresses All nodes must have: Unrestricted connectivity between nodes Internet access for package installation Firewall ports open: TCP/6443 (K3s API) TCP/2379-2380 (etcd) UDP/8472 (VXLAN) TCP/10250 (kubelet) Server Preparation \u00b6 Important Execute these steps on ALL nodes unless specified otherwise. System Updates \u00b6 # Update package list and upgrade system sudo apt update && sudo apt upgrade -y # Install required packages sudo apt install -y \\ curl \\ gnupg \\ nfs-common \\ open-iscsi \\ jq \\ logrotate Configure Log Rotation \u00b6 Create a logrotate configuration for K3s: /etc/logrotate.d/k3s 1 2 3 4 5 6 7 8 9 10 11 12 13 /var/log/k3s/*.log { daily rotate 7 compress delaycompress missingok notifempty create 0640 root root postrotate systemctl restart k3s-server 2 >/dev/null || true systemctl restart k3s-agent 2 >/dev/null || true endscript } System Configuration \u00b6 System Settings 1 2 3 4 5 6 7 8 9 10 11 # Enable and start open-iscsi for Longhorn sudo systemctl enable --now iscsid # Configure sysctl settings cat << EOF | sudo tee /etc/sysctl.d/k3s.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 vm.max_map_count = 262144 EOF sudo sysctl --system K3s Installation \u00b6 Master Node Setup \u00b6 Master Node Only Run these commands ONLY on the master node. Install K3s Server # Download K3s installation script curl -sfL https://get.k3s.io > k3s-install.sh # Install K3s server with HA etcd and VXLAN sudo INSTALL_K3S_VERSION = \"v1.29.1+k3s2\" bash k3s-install.sh server \\ --cluster-init \\ --flannel-backend = vxlan \\ --disable traefik \\ --disable servicelb \\ --disable local-storage \\ --tls-san $( hostname -f ) \\ --write-kubeconfig-mode 644 # Get node token for workers sudo cat /var/lib/rancher/k3s/server/node-token Worker Nodes Setup \u00b6 Worker Nodes Only Replace MASTER_IP and NODE_TOKEN with your actual values. Install K3s Agent # Download K3s installation script curl -sfL https://get.k3s.io > k3s-install.sh # Install K3s agent sudo INSTALL_K3S_VERSION = \"v1.29.1+k3s2\" K3S_URL = \"https://MASTER_IP:6443\" \\ K3S_TOKEN = \"NODE_TOKEN\" bash k3s-install.sh agent Verify Cluster Status \u00b6 Check Nodes Check Pods Check etcd Health kubectl get nodes -o wide kubectl get pods -A kubectl -n kube-system exec -it etcd-master -- etcdctl endpoint health Longhorn Installation \u00b6 Prerequisites Check \u00b6 Run this on all nodes to verify Longhorn requirements: Verify Requirements curl -sSfL https://raw.githubusercontent.com/longhorn/longhorn/v1.6.0/scripts/environment_check.sh | bash Install Longhorn \u00b6 Installation Steps Execute these commands on the master node. Deploy Longhorn # Add Longhorn Helm repository helm repo add longhorn https://charts.longhorn.io helm repo update # Install Longhorn helm install longhorn longhorn/longhorn \\ --namespace longhorn-system \\ --create-namespace \\ --version 1 .6.0 \\ --set defaultSettings.defaultDataPath = \"/var/lib/longhorn\" \\ --set defaultSettings.guaranteedEngineManagerCPU = 5 \\ --set defaultSettings.guaranteedReplicaManagerCPU = 5 Verify Longhorn Installation \u00b6 Check Pods Check StorageClass Access Dashboard kubectl -n longhorn-system get pods kubectl get sc # Port forward Longhorn UI kubectl -n longhorn-system port-forward svc/longhorn-frontend 8000 :80 Access via: http://localhost:8000 Troubleshooting \u00b6 Common Issues \u00b6 Known Problems and Solutions Node Not Ready etcd Issues Longhorn Volume Issues Check K3s service status: sudo systemctl status k3s View K3s logs: sudo journalctl -u k3s Check etcd cluster health: sudo k3s etcd-snapshot ls Verify etcd member list: kubectl -n kube-system exec -it etcd-master -- etcdctl member list Check volume status: kubectl -n longhorn-system get volumes View instance manager logs: kubectl -n longhorn-system logs -l app = longhorn-manager Maintenance \u00b6 Backup Procedures \u00b6 etcd Backup Longhorn Backup # Create etcd snapshot sudo k3s etcd-snapshot save --name etcd-backup- $( date +%Y%m%d ) # Create backup settings kubectl -n longhorn-system apply -f - <<EOF apiVersion: longhorn.io/v1beta1 kind: BackupTarget metadata: name: default spec: backupTargetURL: s3://your-bucket-name@region/path credentialSecret: aws-secret EOF Monitoring Setup \u00b6 Monitoring Stack Consider installing: - Prometheus for metrics collection - Grafana for visualization - Alertmanager for notifications Security Recommendations \u00b6 Network Policies apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : default-deny-all spec : podSelector : {} policyTypes : - Ingress - Egress Pod Security Standards apiVersion : constraints.gatekeeper.sh/v1beta1 kind : K8sPSPPrivilegedContainer metadata : name : no-privileged-containers spec : enforcementAction : deny Next Steps \u00b6 [ ] Configure external load balancer [ ] Set up monitoring and logging [ ] Implement backup strategy [ ] Configure disaster recovery [ ] Set up CI/CD pipelines Need Help? If you encounter any issues: - Check the K3s documentation - Visit the Longhorn documentation - Join the K3s Slack channel","title":"HA K3s Cluster"},{"location":"k3s-ha-cluster/#high-availability-k3s-cluster-setup-guide","text":"","title":"High Availability K3s Cluster Setup Guide"},{"location":"k3s-ha-cluster/#overview","text":"Guide Information Difficulty : Advanced Time Required : ~1 hour Last Updated : March 2024 K3s Version : v1.29.1+k3s2 Longhorn Version : v1.6.0","title":"Overview"},{"location":"k3s-ha-cluster/#architecture-overview","text":"graph TD subgraph \"Control Plane\" A[Master Node<br/>etcd + K3s Server] end subgraph \"Worker Nodes\" B[Worker Node 1<br/>K3s Agent] C[Worker Node 2<br/>K3s Agent] D[Worker Node 3<br/>K3s Agent] end subgraph \"Storage Layer\" E[Longhorn<br/>Distributed Block Storage] end A --> B A --> C A --> D B --> E C --> E D --> E style A fill:#f9f,stroke:#333 style E fill:#bbf,stroke:#333","title":"Architecture Overview"},{"location":"k3s-ha-cluster/#prerequisites","text":"System Requirements Master Node Worker Nodes Network Requirements 2 CPU cores 4GB RAM 40GB disk space Ubuntu 22.04 LTS Static IP address 2 CPU cores 8GB RAM 100GB disk space Ubuntu 22.04 LTS Static IP addresses All nodes must have: Unrestricted connectivity between nodes Internet access for package installation Firewall ports open: TCP/6443 (K3s API) TCP/2379-2380 (etcd) UDP/8472 (VXLAN) TCP/10250 (kubelet)","title":"Prerequisites"},{"location":"k3s-ha-cluster/#server-preparation","text":"Important Execute these steps on ALL nodes unless specified otherwise.","title":"Server Preparation"},{"location":"k3s-ha-cluster/#system-updates","text":"# Update package list and upgrade system sudo apt update && sudo apt upgrade -y # Install required packages sudo apt install -y \\ curl \\ gnupg \\ nfs-common \\ open-iscsi \\ jq \\ logrotate","title":"System Updates"},{"location":"k3s-ha-cluster/#configure-log-rotation","text":"Create a logrotate configuration for K3s: /etc/logrotate.d/k3s 1 2 3 4 5 6 7 8 9 10 11 12 13 /var/log/k3s/*.log { daily rotate 7 compress delaycompress missingok notifempty create 0640 root root postrotate systemctl restart k3s-server 2 >/dev/null || true systemctl restart k3s-agent 2 >/dev/null || true endscript }","title":"Configure Log Rotation"},{"location":"k3s-ha-cluster/#system-configuration","text":"System Settings 1 2 3 4 5 6 7 8 9 10 11 # Enable and start open-iscsi for Longhorn sudo systemctl enable --now iscsid # Configure sysctl settings cat << EOF | sudo tee /etc/sysctl.d/k3s.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 vm.max_map_count = 262144 EOF sudo sysctl --system","title":"System Configuration"},{"location":"k3s-ha-cluster/#k3s-installation","text":"","title":"K3s Installation"},{"location":"k3s-ha-cluster/#master-node-setup","text":"Master Node Only Run these commands ONLY on the master node. Install K3s Server # Download K3s installation script curl -sfL https://get.k3s.io > k3s-install.sh # Install K3s server with HA etcd and VXLAN sudo INSTALL_K3S_VERSION = \"v1.29.1+k3s2\" bash k3s-install.sh server \\ --cluster-init \\ --flannel-backend = vxlan \\ --disable traefik \\ --disable servicelb \\ --disable local-storage \\ --tls-san $( hostname -f ) \\ --write-kubeconfig-mode 644 # Get node token for workers sudo cat /var/lib/rancher/k3s/server/node-token","title":"Master Node Setup"},{"location":"k3s-ha-cluster/#worker-nodes-setup","text":"Worker Nodes Only Replace MASTER_IP and NODE_TOKEN with your actual values. Install K3s Agent # Download K3s installation script curl -sfL https://get.k3s.io > k3s-install.sh # Install K3s agent sudo INSTALL_K3S_VERSION = \"v1.29.1+k3s2\" K3S_URL = \"https://MASTER_IP:6443\" \\ K3S_TOKEN = \"NODE_TOKEN\" bash k3s-install.sh agent","title":"Worker Nodes Setup"},{"location":"k3s-ha-cluster/#verify-cluster-status","text":"Check Nodes Check Pods Check etcd Health kubectl get nodes -o wide kubectl get pods -A kubectl -n kube-system exec -it etcd-master -- etcdctl endpoint health","title":"Verify Cluster Status"},{"location":"k3s-ha-cluster/#longhorn-installation","text":"","title":"Longhorn Installation"},{"location":"k3s-ha-cluster/#prerequisites-check","text":"Run this on all nodes to verify Longhorn requirements: Verify Requirements curl -sSfL https://raw.githubusercontent.com/longhorn/longhorn/v1.6.0/scripts/environment_check.sh | bash","title":"Prerequisites Check"},{"location":"k3s-ha-cluster/#install-longhorn","text":"Installation Steps Execute these commands on the master node. Deploy Longhorn # Add Longhorn Helm repository helm repo add longhorn https://charts.longhorn.io helm repo update # Install Longhorn helm install longhorn longhorn/longhorn \\ --namespace longhorn-system \\ --create-namespace \\ --version 1 .6.0 \\ --set defaultSettings.defaultDataPath = \"/var/lib/longhorn\" \\ --set defaultSettings.guaranteedEngineManagerCPU = 5 \\ --set defaultSettings.guaranteedReplicaManagerCPU = 5","title":"Install Longhorn"},{"location":"k3s-ha-cluster/#verify-longhorn-installation","text":"Check Pods Check StorageClass Access Dashboard kubectl -n longhorn-system get pods kubectl get sc # Port forward Longhorn UI kubectl -n longhorn-system port-forward svc/longhorn-frontend 8000 :80 Access via: http://localhost:8000","title":"Verify Longhorn Installation"},{"location":"k3s-ha-cluster/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"k3s-ha-cluster/#common-issues","text":"Known Problems and Solutions Node Not Ready etcd Issues Longhorn Volume Issues Check K3s service status: sudo systemctl status k3s View K3s logs: sudo journalctl -u k3s Check etcd cluster health: sudo k3s etcd-snapshot ls Verify etcd member list: kubectl -n kube-system exec -it etcd-master -- etcdctl member list Check volume status: kubectl -n longhorn-system get volumes View instance manager logs: kubectl -n longhorn-system logs -l app = longhorn-manager","title":"Common Issues"},{"location":"k3s-ha-cluster/#maintenance","text":"","title":"Maintenance"},{"location":"k3s-ha-cluster/#backup-procedures","text":"etcd Backup Longhorn Backup # Create etcd snapshot sudo k3s etcd-snapshot save --name etcd-backup- $( date +%Y%m%d ) # Create backup settings kubectl -n longhorn-system apply -f - <<EOF apiVersion: longhorn.io/v1beta1 kind: BackupTarget metadata: name: default spec: backupTargetURL: s3://your-bucket-name@region/path credentialSecret: aws-secret EOF","title":"Backup Procedures"},{"location":"k3s-ha-cluster/#monitoring-setup","text":"Monitoring Stack Consider installing: - Prometheus for metrics collection - Grafana for visualization - Alertmanager for notifications","title":"Monitoring Setup"},{"location":"k3s-ha-cluster/#security-recommendations","text":"Network Policies apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : default-deny-all spec : podSelector : {} policyTypes : - Ingress - Egress Pod Security Standards apiVersion : constraints.gatekeeper.sh/v1beta1 kind : K8sPSPPrivilegedContainer metadata : name : no-privileged-containers spec : enforcementAction : deny","title":"Security Recommendations"},{"location":"k3s-ha-cluster/#next-steps","text":"[ ] Configure external load balancer [ ] Set up monitoring and logging [ ] Implement backup strategy [ ] Configure disaster recovery [ ] Set up CI/CD pipelines Need Help? If you encounter any issues: - Check the K3s documentation - Visit the Longhorn documentation - Join the K3s Slack channel","title":"Next Steps"},{"location":"markdown_basics/","text":"Markdown Guide \u00b6 This comprehensive guide will help you master Markdown syntax for creating well-formatted documentation. Each section includes both the Markdown syntax and its rendered output. Basic Syntax \u00b6 1. Headings \u00b6 Markdown provides six levels of headings, using # symbols: # Heading 1 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6 The rendered output looks like this: Heading 1 \u00b6 Heading 2 \u00b6 Heading 3 \u00b6 Heading 4 \u00b6 Heading 5 \u00b6 Heading 6 \u00b6 2. Text Formatting \u00b6 Bold Text \u00b6 **Bold text** or __Bold text__ Bold text or Bold text Italic Text \u00b6 *Italic text* or _Italic text_ Italic text or Italic text Bold and Italic \u00b6 ***Bold and italic*** or ___Bold and italic___ Bold and italic or Bold and italic Strikethrough \u00b6 ~~Strikethrough text~~ ~~Strikethrough text~~ 3. Lists \u00b6 Unordered Lists \u00b6 - First item - Second item - Indented item - Another indented item - Third item First item Second item Indented item Another indented item Third item Ordered Lists \u00b6 1. First item 2. Second item 1. Indented item 2. Another indented item 3. Third item First item Second item Indented item Another indented item Third item 4. Links \u00b6 Basic Links \u00b6 [ Visit GitHub ]( https://github.com ) Visit GitHub Links with Titles \u00b6 [ GitHub ]( https://github.com \"GitHub's Homepage\" ) GitHub Reference-style Links \u00b6 [ GitHub ][ 1 ] [ DevOps ][ 2 ] [ 1 ]: https://github.com [ 2 ]: https://en.wikipedia.org/wiki/DevOps GitHub DevOps 5. Images \u00b6 Basic Image \u00b6 ![ Alt text ]( https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png ) Image with Title \u00b6 ![ GitHub Logo ]( https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png \"GitHub Logo\" ) 6. Code \u00b6 Inline Code \u00b6 Use `git status` to list all changed files. Use git status to list all changed files. Code Blocks \u00b6 ```python def hello_world (): print ( \"Hello, World!\" ) ``` def hello_world (): print ( \"Hello, World!\" ) Syntax Highlighting \u00b6 ```javascript function greet ( name ) { console . log ( `Hello, ${ name } !` ); } ``` function greet ( name ) { console . log ( `Hello, ${ name } !` ); } 7. Tables \u00b6 | Left-aligned | Center-aligned | Right-aligned | |:-------------|:-------------:|-------------:| | Content | Content | Content | | Left | Center | Right | Left-aligned Center-aligned Right-aligned Content Content Content Left Center Right 8. Blockquotes \u00b6 Simple Blockquote \u00b6 > This is a blockquote This is a blockquote Nested Blockquotes \u00b6 > First level >> Second level >>> Third level First level Second level Third level 9. Task Lists \u00b6 - [x] Completed task - [ ] Incomplete task - [x] Completed subtask - [ ] Incomplete subtask [x] Completed task [ ] Incomplete task [x] Completed subtask [ ] Incomplete subtask 10. Horizontal Rules \u00b6 Any of these will create a horizontal rule: --- *** ___ 11. Escaping Characters \u00b6 Use backslash to escape special characters: \\* Not italic \\* \\` Not code \\` \\[ Not a link \\] * Not italic * ` Not code ` [ Not a link ] 12. Extended Syntax (with Material for MkDocs) \u00b6 Highlighting Text \u00b6 ==Highlighted text== ==Highlighted text== Footnotes \u00b6 Here's a sentence with a footnote[^1]. [ ^1 ]: This is the footnote. Here's a sentence with a footnote 1 . Definition Lists \u00b6 term : definition term definition Emoji \u00b6 :smile: :heart: :thumbsup: :smile: :heart: :thumbsup: Best Practices \u00b6 Consistency : Use consistent formatting throughout your document Spacing : Add blank lines before and after headings Headers : Use proper header hierarchy (don't skip levels) Lists : Keep them simple and nested no more than three levels Code Blocks : Always specify the language for syntax highlighting Links : Use descriptive text rather than \"click here\" Images : Always include alt text for accessibility Common Pitfalls to Avoid \u00b6 Forgetting to add two spaces for line breaks Incorrect nesting of lists Missing blank lines before and after lists and code blocks Improper escaping of special characters Inconsistent heading hierarchy Tools and Resources \u00b6 Markdown Editors : Visual Studio Code with Markdown extensions Typora StackEdit (web-based) Online Validators : MarkdownLint Dillinger Cheat Sheets : GitHub Markdown Guide Markdown Guide This is the footnote. \u21a9","title":"Markdown Guide"},{"location":"markdown_basics/#markdown-guide","text":"This comprehensive guide will help you master Markdown syntax for creating well-formatted documentation. Each section includes both the Markdown syntax and its rendered output.","title":"Markdown Guide"},{"location":"markdown_basics/#basic-syntax","text":"","title":"Basic Syntax"},{"location":"markdown_basics/#1-headings","text":"Markdown provides six levels of headings, using # symbols: # Heading 1 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6 The rendered output looks like this:","title":"1. Headings"},{"location":"markdown_basics/#heading-1","text":"","title":"Heading 1"},{"location":"markdown_basics/#heading-2","text":"","title":"Heading 2"},{"location":"markdown_basics/#heading-3","text":"","title":"Heading 3"},{"location":"markdown_basics/#heading-4","text":"","title":"Heading 4"},{"location":"markdown_basics/#heading-5","text":"","title":"Heading 5"},{"location":"markdown_basics/#heading-6","text":"","title":"Heading 6"},{"location":"markdown_basics/#2-text-formatting","text":"","title":"2. Text Formatting"},{"location":"markdown_basics/#bold-text","text":"**Bold text** or __Bold text__ Bold text or Bold text","title":"Bold Text"},{"location":"markdown_basics/#italic-text","text":"*Italic text* or _Italic text_ Italic text or Italic text","title":"Italic Text"},{"location":"markdown_basics/#bold-and-italic","text":"***Bold and italic*** or ___Bold and italic___ Bold and italic or Bold and italic","title":"Bold and Italic"},{"location":"markdown_basics/#strikethrough","text":"~~Strikethrough text~~ ~~Strikethrough text~~","title":"Strikethrough"},{"location":"markdown_basics/#3-lists","text":"","title":"3. Lists"},{"location":"markdown_basics/#unordered-lists","text":"- First item - Second item - Indented item - Another indented item - Third item First item Second item Indented item Another indented item Third item","title":"Unordered Lists"},{"location":"markdown_basics/#ordered-lists","text":"1. First item 2. Second item 1. Indented item 2. Another indented item 3. Third item First item Second item Indented item Another indented item Third item","title":"Ordered Lists"},{"location":"markdown_basics/#4-links","text":"","title":"4. Links"},{"location":"markdown_basics/#basic-links","text":"[ Visit GitHub ]( https://github.com ) Visit GitHub","title":"Basic Links"},{"location":"markdown_basics/#links-with-titles","text":"[ GitHub ]( https://github.com \"GitHub's Homepage\" ) GitHub","title":"Links with Titles"},{"location":"markdown_basics/#reference-style-links","text":"[ GitHub ][ 1 ] [ DevOps ][ 2 ] [ 1 ]: https://github.com [ 2 ]: https://en.wikipedia.org/wiki/DevOps GitHub DevOps","title":"Reference-style Links"},{"location":"markdown_basics/#5-images","text":"","title":"5. Images"},{"location":"markdown_basics/#basic-image","text":"![ Alt text ]( https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png )","title":"Basic Image"},{"location":"markdown_basics/#image-with-title","text":"![ GitHub Logo ]( https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png \"GitHub Logo\" )","title":"Image with Title"},{"location":"markdown_basics/#6-code","text":"","title":"6. Code"},{"location":"markdown_basics/#inline-code","text":"Use `git status` to list all changed files. Use git status to list all changed files.","title":"Inline Code"},{"location":"markdown_basics/#code-blocks","text":"```python def hello_world (): print ( \"Hello, World!\" ) ``` def hello_world (): print ( \"Hello, World!\" )","title":"Code Blocks"},{"location":"markdown_basics/#syntax-highlighting","text":"```javascript function greet ( name ) { console . log ( `Hello, ${ name } !` ); } ``` function greet ( name ) { console . log ( `Hello, ${ name } !` ); }","title":"Syntax Highlighting"},{"location":"markdown_basics/#7-tables","text":"| Left-aligned | Center-aligned | Right-aligned | |:-------------|:-------------:|-------------:| | Content | Content | Content | | Left | Center | Right | Left-aligned Center-aligned Right-aligned Content Content Content Left Center Right","title":"7. Tables"},{"location":"markdown_basics/#8-blockquotes","text":"","title":"8. Blockquotes"},{"location":"markdown_basics/#simple-blockquote","text":"> This is a blockquote This is a blockquote","title":"Simple Blockquote"},{"location":"markdown_basics/#nested-blockquotes","text":"> First level >> Second level >>> Third level First level Second level Third level","title":"Nested Blockquotes"},{"location":"markdown_basics/#9-task-lists","text":"- [x] Completed task - [ ] Incomplete task - [x] Completed subtask - [ ] Incomplete subtask [x] Completed task [ ] Incomplete task [x] Completed subtask [ ] Incomplete subtask","title":"9. Task Lists"},{"location":"markdown_basics/#10-horizontal-rules","text":"Any of these will create a horizontal rule: --- *** ___","title":"10. Horizontal Rules"},{"location":"markdown_basics/#11-escaping-characters","text":"Use backslash to escape special characters: \\* Not italic \\* \\` Not code \\` \\[ Not a link \\] * Not italic * ` Not code ` [ Not a link ]","title":"11. Escaping Characters"},{"location":"markdown_basics/#12-extended-syntax-with-material-for-mkdocs","text":"","title":"12. Extended Syntax (with Material for MkDocs)"},{"location":"markdown_basics/#highlighting-text","text":"==Highlighted text== ==Highlighted text==","title":"Highlighting Text"},{"location":"markdown_basics/#footnotes","text":"Here's a sentence with a footnote[^1]. [ ^1 ]: This is the footnote. Here's a sentence with a footnote 1 .","title":"Footnotes"},{"location":"markdown_basics/#definition-lists","text":"term : definition term definition","title":"Definition Lists"},{"location":"markdown_basics/#emoji","text":":smile: :heart: :thumbsup: :smile: :heart: :thumbsup:","title":"Emoji"},{"location":"markdown_basics/#best-practices","text":"Consistency : Use consistent formatting throughout your document Spacing : Add blank lines before and after headings Headers : Use proper header hierarchy (don't skip levels) Lists : Keep them simple and nested no more than three levels Code Blocks : Always specify the language for syntax highlighting Links : Use descriptive text rather than \"click here\" Images : Always include alt text for accessibility","title":"Best Practices"},{"location":"markdown_basics/#common-pitfalls-to-avoid","text":"Forgetting to add two spaces for line breaks Incorrect nesting of lists Missing blank lines before and after lists and code blocks Improper escaping of special characters Inconsistent heading hierarchy","title":"Common Pitfalls to Avoid"},{"location":"markdown_basics/#tools-and-resources","text":"Markdown Editors : Visual Studio Code with Markdown extensions Typora StackEdit (web-based) Online Validators : MarkdownLint Dillinger Cheat Sheets : GitHub Markdown Guide Markdown Guide This is the footnote. \u21a9","title":"Tools and Resources"},{"location":"multipass-k8s-cluster/","text":"Local Kubernetes Cluster with Multipass \u00b6 Overview \u00b6 Guide Information Difficulty : Intermediate Time Required : ~30 minutes Last Updated : March 2024 Table of Contents \u00b6 Setup Multipass Provision Virtual Machines Server Preparation Configure System Settings Install Kubernetes Components Initialize Cluster Setup Network Interface Join Worker Nodes Verify Cluster Troubleshooting Cluster Maintenance Architecture \u00b6 graph TD A[Host Ubuntu 24.04] --> B[Multipass] B --> C[Master Node<br/>4GB RAM, 2 CPU] B --> D[Worker1<br/>4GB RAM, 2 CPU] B --> E[Worker2<br/>4GB RAM, 2 CPU] C --> F[Control Plane] F --> G[API Server] F --> H[etcd] F --> I[Controller Manager] F --> J[Scheduler] D --> K[kubelet] D --> L[containerd] E --> M[kubelet] E --> N[containerd] Setup Multipass \u00b6 Quick Setup Multipass provides a fast way to spin up Ubuntu VMs. It's lightweight and perfect for local Kubernetes clusters. Install Multipass Verify Installation List Available Images sudo snap install multipass multipass version multipass find Provision Virtual Machines \u00b6 Resource Allocation We'll create one master node and two worker nodes. Adjust the resources based on your system capabilities. Create Cluster Nodes # Create master node multipass launch --name master --cpus 2 --mem 4G --disk 20G # Create worker nodes multipass launch --name worker1 --cpus 2 --mem 4G --disk 20G multipass launch --name worker2 --cpus 2 --mem 4G --disk 20G Expected Output Launched: master Launched: worker1 Launched: worker2 Access Nodes \u00b6 Master Node Worker Node 1 Worker Node 2 multipass shell master multipass shell worker1 multipass shell worker2 Get Node IPs \u00b6 multipass list Server Preparation \u00b6 Important Run these commands on ALL nodes (master and workers). Update System Install Dependencies Setup Docker Repository sudo apt update && sudo apt upgrade -y sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release sudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo tee /etc/apt/keyrings/docker.asc > /dev/null echo \"deb [arch= $( dpkg --print-architecture ) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Install Containerd \u00b6 Install and Configure Containerd 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Install containerd sudo apt update sudo apt install -y containerd.io # Enable and start containerd sudo systemctl enable containerd sudo systemctl start containerd # Generate default config sudo mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml # Modify containerd configuration sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml sudo sed -i 's/^disabled_plugins = \\[\"cri\"\\]/#disabled_plugins = \\[\"cri\"\\]/' /etc/containerd/config.toml # Restart containerd sudo systemctl restart containerd Configure System Settings \u00b6 Critical Step Skipping these configurations may result in cluster initialization failures. Disable Swap Load Kernel Modules Configure Sysctl sudo swapoff -a sudo sed -i '/swap/d' /etc/fstab cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system Install Kubernetes Components \u00b6 Version Information This guide uses Kubernetes v1.32. Adjust version numbers as needed. Install Kubernetes Tools # Add Kubernetes repository curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list # Install required packages sudo apt update sudo apt install -y kubelet kubeadm kubectl # Prevent accidental upgrades sudo apt-mark hold kubelet kubeadm kubectl # Enable kubelet sudo systemctl enable kubelet sudo systemctl start kubelet Initialize Cluster \u00b6 Master Node Only Run these commands ONLY on the master node. Initialize Kubernetes Cluster # Initialize cluster sudo kubeadm init --pod-network-cidr = 10 .244.0.0/16 # Setup kubeconfig mkdir -p $HOME /.kube sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config Save the Join Command The initialization will output a kubeadm join command. Save this for joining worker nodes. Setup Network Interface \u00b6 Install Flannel CNI Verify Installation kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml kubectl get pods -n kube-flannel Join Worker Nodes \u00b6 Worker Nodes Only Run these commands on each worker node. Get Join Command (Master) Join Cluster (Workers) kubeadm token create --print-join-command sudo kubeadm join <master-ip>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash> Verify Cluster \u00b6 Check Node Status Check Pods kubectl get nodes kubectl get pods -A Troubleshooting \u00b6 Common Issues Node Not Ready Join Command Issues Pod Network Issues Check CNI pods: kubectl get pods -n kube-system Check kubelet status: systemctl status kubelet View kubelet logs: journalctl -xeu kubelet Generate new token: kubeadm token create Get discovery token CA cert hash: openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | \\ openssl rsa -pubin -outform der 2 >/dev/null | \\ openssl dgst -sha256 -hex | sed 's/^.* //' Check flannel pods: kubectl get pods -n kube-flannel Check flannel logs: kubectl logs -n kube-flannel <pod-name> Cluster Maintenance \u00b6 Backup Procedures \u00b6 Backup etcd sudo apt install etcd-client ETCDCTL_API = 3 etcdctl --endpoints = https://127.0.0.1:2379 \\ --cacert = /etc/kubernetes/pki/etcd/ca.crt \\ --cert = /etc/kubernetes/pki/etcd/server.crt \\ --key = /etc/kubernetes/pki/etcd/server.key \\ snapshot save snapshot.db Scaling the Cluster \u00b6 To add more worker nodes: Create new VM using multipass Follow server preparation steps Join the cluster using the join command Cleanup \u00b6 Delete Node Delete VM # On master node kubectl drain <node-name> --ignore-daemonsets kubectl delete node <node-name> # On worker node sudo kubeadm reset multipass delete <vm-name> multipass purge Security Best Practices \u00b6 Keep Kubernetes version updated Use Network Policies Enable RBAC Regularly rotate certificates Monitor cluster with security tools Next Steps \u00b6 Deploy sample applications Setup monitoring with Prometheus and Grafana Configure persistent storage Implement high availability Need Help? If you encounter any issues, check the official Kubernetes documentation or open an issue in the repository.","title":"Multipass Local Cluster"},{"location":"multipass-k8s-cluster/#local-kubernetes-cluster-with-multipass","text":"","title":"Local Kubernetes Cluster with Multipass"},{"location":"multipass-k8s-cluster/#overview","text":"Guide Information Difficulty : Intermediate Time Required : ~30 minutes Last Updated : March 2024","title":"Overview"},{"location":"multipass-k8s-cluster/#table-of-contents","text":"Setup Multipass Provision Virtual Machines Server Preparation Configure System Settings Install Kubernetes Components Initialize Cluster Setup Network Interface Join Worker Nodes Verify Cluster Troubleshooting Cluster Maintenance","title":"Table of Contents"},{"location":"multipass-k8s-cluster/#architecture","text":"graph TD A[Host Ubuntu 24.04] --> B[Multipass] B --> C[Master Node<br/>4GB RAM, 2 CPU] B --> D[Worker1<br/>4GB RAM, 2 CPU] B --> E[Worker2<br/>4GB RAM, 2 CPU] C --> F[Control Plane] F --> G[API Server] F --> H[etcd] F --> I[Controller Manager] F --> J[Scheduler] D --> K[kubelet] D --> L[containerd] E --> M[kubelet] E --> N[containerd]","title":"Architecture"},{"location":"multipass-k8s-cluster/#setup-multipass","text":"Quick Setup Multipass provides a fast way to spin up Ubuntu VMs. It's lightweight and perfect for local Kubernetes clusters. Install Multipass Verify Installation List Available Images sudo snap install multipass multipass version multipass find","title":"Setup Multipass"},{"location":"multipass-k8s-cluster/#provision-virtual-machines","text":"Resource Allocation We'll create one master node and two worker nodes. Adjust the resources based on your system capabilities. Create Cluster Nodes # Create master node multipass launch --name master --cpus 2 --mem 4G --disk 20G # Create worker nodes multipass launch --name worker1 --cpus 2 --mem 4G --disk 20G multipass launch --name worker2 --cpus 2 --mem 4G --disk 20G Expected Output Launched: master Launched: worker1 Launched: worker2","title":"Provision Virtual Machines"},{"location":"multipass-k8s-cluster/#access-nodes","text":"Master Node Worker Node 1 Worker Node 2 multipass shell master multipass shell worker1 multipass shell worker2","title":"Access Nodes"},{"location":"multipass-k8s-cluster/#get-node-ips","text":"multipass list","title":"Get Node IPs"},{"location":"multipass-k8s-cluster/#server-preparation","text":"Important Run these commands on ALL nodes (master and workers). Update System Install Dependencies Setup Docker Repository sudo apt update && sudo apt upgrade -y sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release sudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo tee /etc/apt/keyrings/docker.asc > /dev/null echo \"deb [arch= $( dpkg --print-architecture ) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null","title":"Server Preparation"},{"location":"multipass-k8s-cluster/#install-containerd","text":"Install and Configure Containerd 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Install containerd sudo apt update sudo apt install -y containerd.io # Enable and start containerd sudo systemctl enable containerd sudo systemctl start containerd # Generate default config sudo mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml # Modify containerd configuration sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml sudo sed -i 's/^disabled_plugins = \\[\"cri\"\\]/#disabled_plugins = \\[\"cri\"\\]/' /etc/containerd/config.toml # Restart containerd sudo systemctl restart containerd","title":"Install Containerd"},{"location":"multipass-k8s-cluster/#configure-system-settings","text":"Critical Step Skipping these configurations may result in cluster initialization failures. Disable Swap Load Kernel Modules Configure Sysctl sudo swapoff -a sudo sed -i '/swap/d' /etc/fstab cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system","title":"Configure System Settings"},{"location":"multipass-k8s-cluster/#install-kubernetes-components","text":"Version Information This guide uses Kubernetes v1.32. Adjust version numbers as needed. Install Kubernetes Tools # Add Kubernetes repository curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list # Install required packages sudo apt update sudo apt install -y kubelet kubeadm kubectl # Prevent accidental upgrades sudo apt-mark hold kubelet kubeadm kubectl # Enable kubelet sudo systemctl enable kubelet sudo systemctl start kubelet","title":"Install Kubernetes Components"},{"location":"multipass-k8s-cluster/#initialize-cluster","text":"Master Node Only Run these commands ONLY on the master node. Initialize Kubernetes Cluster # Initialize cluster sudo kubeadm init --pod-network-cidr = 10 .244.0.0/16 # Setup kubeconfig mkdir -p $HOME /.kube sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config Save the Join Command The initialization will output a kubeadm join command. Save this for joining worker nodes.","title":"Initialize Cluster"},{"location":"multipass-k8s-cluster/#setup-network-interface","text":"Install Flannel CNI Verify Installation kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml kubectl get pods -n kube-flannel","title":"Setup Network Interface"},{"location":"multipass-k8s-cluster/#join-worker-nodes","text":"Worker Nodes Only Run these commands on each worker node. Get Join Command (Master) Join Cluster (Workers) kubeadm token create --print-join-command sudo kubeadm join <master-ip>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash>","title":"Join Worker Nodes"},{"location":"multipass-k8s-cluster/#verify-cluster","text":"Check Node Status Check Pods kubectl get nodes kubectl get pods -A","title":"Verify Cluster"},{"location":"multipass-k8s-cluster/#troubleshooting","text":"Common Issues Node Not Ready Join Command Issues Pod Network Issues Check CNI pods: kubectl get pods -n kube-system Check kubelet status: systemctl status kubelet View kubelet logs: journalctl -xeu kubelet Generate new token: kubeadm token create Get discovery token CA cert hash: openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | \\ openssl rsa -pubin -outform der 2 >/dev/null | \\ openssl dgst -sha256 -hex | sed 's/^.* //' Check flannel pods: kubectl get pods -n kube-flannel Check flannel logs: kubectl logs -n kube-flannel <pod-name>","title":"Troubleshooting"},{"location":"multipass-k8s-cluster/#cluster-maintenance","text":"","title":"Cluster Maintenance"},{"location":"multipass-k8s-cluster/#backup-procedures","text":"Backup etcd sudo apt install etcd-client ETCDCTL_API = 3 etcdctl --endpoints = https://127.0.0.1:2379 \\ --cacert = /etc/kubernetes/pki/etcd/ca.crt \\ --cert = /etc/kubernetes/pki/etcd/server.crt \\ --key = /etc/kubernetes/pki/etcd/server.key \\ snapshot save snapshot.db","title":"Backup Procedures"},{"location":"multipass-k8s-cluster/#scaling-the-cluster","text":"To add more worker nodes: Create new VM using multipass Follow server preparation steps Join the cluster using the join command","title":"Scaling the Cluster"},{"location":"multipass-k8s-cluster/#cleanup","text":"Delete Node Delete VM # On master node kubectl drain <node-name> --ignore-daemonsets kubectl delete node <node-name> # On worker node sudo kubeadm reset multipass delete <vm-name> multipass purge","title":"Cleanup"},{"location":"multipass-k8s-cluster/#security-best-practices","text":"Keep Kubernetes version updated Use Network Policies Enable RBAC Regularly rotate certificates Monitor cluster with security tools","title":"Security Best Practices"},{"location":"multipass-k8s-cluster/#next-steps","text":"Deploy sample applications Setup monitoring with Prometheus and Grafana Configure persistent storage Implement high availability Need Help? If you encounter any issues, check the official Kubernetes documentation or open an issue in the repository.","title":"Next Steps"},{"location":"versioning/","text":"1. Git SHA (Commit Hash) \u00b6 Format : image:git-sha Example : myapp:a1b2c3d Pros: \u00b6 Precise tracking to source code Immutable and unique Easy to debug and rollback Perfect for development environments Cons: \u00b6 Not human-readable Difficult to determine version order No immediate indication of stability level Detailed Explanation: \u00b6 Git SHA versioning uses the unique hash identifier that Git generates for each commit in your repository. When you build a Docker image using this approach, you take the first few characters (usually 7-8) of the commit hash and use it as your image tag. This method creates an unbreakable link between your source code and the Docker image, making it extremely useful for debugging and traceability. For instance, if you discover an issue in production, you can immediately identify the exact code commit that produced that image. However, these hashes are not human-friendly - you can't tell at a glance which version came first or what changes it contains. This makes it less ideal for release management but perfect for development and testing environments where precise code tracking is crucial. 2. Semantic Versioning \u00b6 Format : image:MAJOR.MINOR.PATCH Example : myapp:1.2.3 Pros: \u00b6 Clear indication of change magnitude Well understood by developers Good for stable releases Easy to automate with conventional commits Cons: \u00b6 Can be subjective (what constitutes a breaking change?) Multiple tags might point to same image Detailed Explanation: \u00b6 Semantic Versioning follows a structured numbering system with three components: MAJOR.MINOR.PATCH. Each component has a specific meaning - MAJOR versions indicate breaking changes that might require users to modify their code, MINOR versions add new features while maintaining backward compatibility, and PATCH versions represent bug fixes. This system is particularly valuable when your Docker image contains an application or service that other systems depend on. Users can quickly understand the impact of upgrading to a new version. For example, if you're currently using version 1.2.3 and see version 1.2.4, you know it's safe to upgrade since it's just a patch. However, if you see version 2.0.0, you know to carefully review the changes as it contains breaking changes. The main challenge with SemVer is maintaining discipline in version number assignment - teams need to consistently agree on what constitutes a breaking change versus a minor feature addition. 3. Git Tag Based \u00b6 Format : image:v1.2.3 Example : myapp:v1.2.3 Pros: \u00b6 Direct correlation with Git releases Good for release automation Clear release history Cons: \u00b6 Requires disciplined tag management May need additional CI/CD configuration Can be confusing with multiple release branches Detailed Explanation: \u00b6 Git tag based versioning aligns your Docker image versions with your Git repository's release tags. This approach creates a natural workflow where creating a Git tag automatically triggers a new Docker image build with the same version. It's particularly powerful when combined with semantic versioning - for example, tagging a release as v1.2.3 in Git automatically produces a Docker image tagged 1.2.3. This method works exceptionally well with automated release processes and provides clear documentation of your release history. The challenge comes when managing multiple release branches or when hotfixes need to be applied to older versions. You need robust processes to handle these scenarios and ensure tags are created consistently across branches. 4. Environment Based \u00b6 Format : image:env-timestamp Example : myapp:prod-20250302 Pros: \u00b6 Clear deployment target Easy to track when image was built Good for environment-specific configurations Cons: \u00b6 Less precise source tracking Potential confusion with multiple deployments per day Additional storage overhead Detailed Explanation: \u00b6 Environment based versioning adds context about where and when an image is intended to be used. This approach often combines an environment identifier with a timestamp or build number, such as prod-20250302 or staging-build123. This strategy is particularly useful in organizations with complex deployment pipelines involving multiple environments (development, staging, QA, production). It makes it immediately clear which images are approved for which environments and when they were built. The timestamp component helps track the age of deployments and can be crucial for compliance requirements. However, this approach can lead to image proliferation and doesn't inherently track the relationship between images across environments. You might need additional tooling to know that prod-20250302 and dev-20250301 contain the same code. 5. Latest Tag \u00b6 Format : image:latest Example : myapp:latest Pros: \u00b6 Simple to use Always points to newest version Good for development Cons: \u00b6 Unreliable for production Can lead to inconsistent deployments Hard to track actual version deployed Detailed Explanation: \u00b6 The 'latest' tag is a special convention in Docker that typically points to the most recent version of an image. While simple and convenient, especially during development, it's considered an anti-pattern for production use. The main issue is its mutability - the 'latest' tag can point to different images at different times, making it impossible to guarantee consistency across deployments. For example, if two developers pull 'latest' at different times, they might get different versions. This can lead to the \"it works on my machine\" problem and make debugging extremely difficult. Latest tags are best reserved for development environments or automated testing where having the newest version is more important than version stability. Best Practices \u00b6 For CI/CD Pipeline: \u00b6 Always use immutable tags Include build metadata (e.g., myapp:1.2.3-a1b2c3d ) Implement automated version bumping Use multi-stage builds to reduce image size For Production: \u00b6 Never use :latest tag Always specify exact version Implement image scanning Keep image history for rollbacks For ArgoCD: \u00b6 Use specific versions in manifests Implement automatic image updater Configure image pull policies Set up proper RBAC for image repositories Recommended Strategy \u00b6 For a robust production setup, combine multiple approaches: myapp:1.2.3-a1b2c3d-20250302 \u2502 \u2502 \u2502 \u2514\u2500 Build timestamp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Git SHA (short) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Semantic version \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Image name This provides: - Clear version tracking - Easy rollbacks - Build traceability - Deployment history Combined Strategy Explanation: \u00b6 Many organizations adopt a hybrid approach that combines multiple versioning strategies to get the best of each. A common pattern is to tag each image with both a semantic version and a Git SHA (e.g., myapp:1.2.3-a1b2c3d). This provides both human-readable version information and precise code traceability. Some teams also add build metadata like timestamps or CI build numbers. While this approach provides comprehensive information, it requires more sophisticated build and deployment automation to manage the multiple tags correctly. Automation Tips \u00b6 Use GitHub Actions to automatically: Generate versions based on conventional commits Tag Docker images Push to registry Update deployment manifests Use ArgoCD to: Monitor image repositories Auto-sync new versions Maintain deployment history Enable easy rollbacks Key Stakeholder Considerations \u00b6 The key to successful Docker image versioning is choosing a strategy that balances the needs of different stakeholders: - Developers need to quickly identify and debug issues - Operations teams need stable, traceable deployments - Release managers need clear version progression - Security teams need audit capabilities - End users need clear upgrade paths","title":"Versioning Guide"},{"location":"versioning/#1-git-sha-commit-hash","text":"Format : image:git-sha Example : myapp:a1b2c3d","title":"1. Git SHA (Commit Hash)"},{"location":"versioning/#pros","text":"Precise tracking to source code Immutable and unique Easy to debug and rollback Perfect for development environments","title":"Pros:"},{"location":"versioning/#cons","text":"Not human-readable Difficult to determine version order No immediate indication of stability level","title":"Cons:"},{"location":"versioning/#detailed-explanation","text":"Git SHA versioning uses the unique hash identifier that Git generates for each commit in your repository. When you build a Docker image using this approach, you take the first few characters (usually 7-8) of the commit hash and use it as your image tag. This method creates an unbreakable link between your source code and the Docker image, making it extremely useful for debugging and traceability. For instance, if you discover an issue in production, you can immediately identify the exact code commit that produced that image. However, these hashes are not human-friendly - you can't tell at a glance which version came first or what changes it contains. This makes it less ideal for release management but perfect for development and testing environments where precise code tracking is crucial.","title":"Detailed Explanation:"},{"location":"versioning/#2-semantic-versioning","text":"Format : image:MAJOR.MINOR.PATCH Example : myapp:1.2.3","title":"2. Semantic Versioning"},{"location":"versioning/#pros_1","text":"Clear indication of change magnitude Well understood by developers Good for stable releases Easy to automate with conventional commits","title":"Pros:"},{"location":"versioning/#cons_1","text":"Can be subjective (what constitutes a breaking change?) Multiple tags might point to same image","title":"Cons:"},{"location":"versioning/#detailed-explanation_1","text":"Semantic Versioning follows a structured numbering system with three components: MAJOR.MINOR.PATCH. Each component has a specific meaning - MAJOR versions indicate breaking changes that might require users to modify their code, MINOR versions add new features while maintaining backward compatibility, and PATCH versions represent bug fixes. This system is particularly valuable when your Docker image contains an application or service that other systems depend on. Users can quickly understand the impact of upgrading to a new version. For example, if you're currently using version 1.2.3 and see version 1.2.4, you know it's safe to upgrade since it's just a patch. However, if you see version 2.0.0, you know to carefully review the changes as it contains breaking changes. The main challenge with SemVer is maintaining discipline in version number assignment - teams need to consistently agree on what constitutes a breaking change versus a minor feature addition.","title":"Detailed Explanation:"},{"location":"versioning/#3-git-tag-based","text":"Format : image:v1.2.3 Example : myapp:v1.2.3","title":"3. Git Tag Based"},{"location":"versioning/#pros_2","text":"Direct correlation with Git releases Good for release automation Clear release history","title":"Pros:"},{"location":"versioning/#cons_2","text":"Requires disciplined tag management May need additional CI/CD configuration Can be confusing with multiple release branches","title":"Cons:"},{"location":"versioning/#detailed-explanation_2","text":"Git tag based versioning aligns your Docker image versions with your Git repository's release tags. This approach creates a natural workflow where creating a Git tag automatically triggers a new Docker image build with the same version. It's particularly powerful when combined with semantic versioning - for example, tagging a release as v1.2.3 in Git automatically produces a Docker image tagged 1.2.3. This method works exceptionally well with automated release processes and provides clear documentation of your release history. The challenge comes when managing multiple release branches or when hotfixes need to be applied to older versions. You need robust processes to handle these scenarios and ensure tags are created consistently across branches.","title":"Detailed Explanation:"},{"location":"versioning/#4-environment-based","text":"Format : image:env-timestamp Example : myapp:prod-20250302","title":"4. Environment Based"},{"location":"versioning/#pros_3","text":"Clear deployment target Easy to track when image was built Good for environment-specific configurations","title":"Pros:"},{"location":"versioning/#cons_3","text":"Less precise source tracking Potential confusion with multiple deployments per day Additional storage overhead","title":"Cons:"},{"location":"versioning/#detailed-explanation_3","text":"Environment based versioning adds context about where and when an image is intended to be used. This approach often combines an environment identifier with a timestamp or build number, such as prod-20250302 or staging-build123. This strategy is particularly useful in organizations with complex deployment pipelines involving multiple environments (development, staging, QA, production). It makes it immediately clear which images are approved for which environments and when they were built. The timestamp component helps track the age of deployments and can be crucial for compliance requirements. However, this approach can lead to image proliferation and doesn't inherently track the relationship between images across environments. You might need additional tooling to know that prod-20250302 and dev-20250301 contain the same code.","title":"Detailed Explanation:"},{"location":"versioning/#5-latest-tag","text":"Format : image:latest Example : myapp:latest","title":"5. Latest Tag"},{"location":"versioning/#pros_4","text":"Simple to use Always points to newest version Good for development","title":"Pros:"},{"location":"versioning/#cons_4","text":"Unreliable for production Can lead to inconsistent deployments Hard to track actual version deployed","title":"Cons:"},{"location":"versioning/#detailed-explanation_4","text":"The 'latest' tag is a special convention in Docker that typically points to the most recent version of an image. While simple and convenient, especially during development, it's considered an anti-pattern for production use. The main issue is its mutability - the 'latest' tag can point to different images at different times, making it impossible to guarantee consistency across deployments. For example, if two developers pull 'latest' at different times, they might get different versions. This can lead to the \"it works on my machine\" problem and make debugging extremely difficult. Latest tags are best reserved for development environments or automated testing where having the newest version is more important than version stability.","title":"Detailed Explanation:"},{"location":"versioning/#best-practices","text":"","title":"Best Practices"},{"location":"versioning/#for-cicd-pipeline","text":"Always use immutable tags Include build metadata (e.g., myapp:1.2.3-a1b2c3d ) Implement automated version bumping Use multi-stage builds to reduce image size","title":"For CI/CD Pipeline:"},{"location":"versioning/#for-production","text":"Never use :latest tag Always specify exact version Implement image scanning Keep image history for rollbacks","title":"For Production:"},{"location":"versioning/#for-argocd","text":"Use specific versions in manifests Implement automatic image updater Configure image pull policies Set up proper RBAC for image repositories","title":"For ArgoCD:"},{"location":"versioning/#recommended-strategy","text":"For a robust production setup, combine multiple approaches: myapp:1.2.3-a1b2c3d-20250302 \u2502 \u2502 \u2502 \u2514\u2500 Build timestamp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Git SHA (short) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Semantic version \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Image name This provides: - Clear version tracking - Easy rollbacks - Build traceability - Deployment history","title":"Recommended Strategy"},{"location":"versioning/#combined-strategy-explanation","text":"Many organizations adopt a hybrid approach that combines multiple versioning strategies to get the best of each. A common pattern is to tag each image with both a semantic version and a Git SHA (e.g., myapp:1.2.3-a1b2c3d). This provides both human-readable version information and precise code traceability. Some teams also add build metadata like timestamps or CI build numbers. While this approach provides comprehensive information, it requires more sophisticated build and deployment automation to manage the multiple tags correctly.","title":"Combined Strategy Explanation:"},{"location":"versioning/#automation-tips","text":"Use GitHub Actions to automatically: Generate versions based on conventional commits Tag Docker images Push to registry Update deployment manifests Use ArgoCD to: Monitor image repositories Auto-sync new versions Maintain deployment history Enable easy rollbacks","title":"Automation Tips"},{"location":"versioning/#key-stakeholder-considerations","text":"The key to successful Docker image versioning is choosing a strategy that balances the needs of different stakeholders: - Developers need to quickly identify and debug issues - Operations teams need stable, traceable deployments - Release managers need clear version progression - Security teams need audit capabilities - End users need clear upgrade paths","title":"Key Stakeholder Considerations"},{"location":"documentation/","text":"Documentation \u00b6 Welcome to the documentation section! Here you'll find detailed guides and tutorials on various DevOps topics. Available Guides \u00b6 Markdown Guide : Learn markdown syntax for better documentation Versioning Guide : Understand different versioning strategies and best practices More guides coming soon!","title":"Overview"},{"location":"documentation/#documentation","text":"Welcome to the documentation section! Here you'll find detailed guides and tutorials on various DevOps topics.","title":"Documentation"},{"location":"documentation/#available-guides","text":"Markdown Guide : Learn markdown syntax for better documentation Versioning Guide : Understand different versioning strategies and best practices More guides coming soon!","title":"Available Guides"},{"location":"documentation/cicd/","text":"CI/CD Pipelines \u00b6 Coming soon! This section will contain guides and tutorials about Continuous Integration and Continuous Deployment.","title":"Overview"},{"location":"documentation/cicd/#cicd-pipelines","text":"Coming soon! This section will contain guides and tutorials about Continuous Integration and Continuous Deployment.","title":"CI/CD Pipelines"},{"location":"documentation/infrastructure/","text":"Infrastructure \u00b6 Coming soon! This section will contain guides and tutorials about infrastructure management and cloud services.","title":"Overview"},{"location":"documentation/infrastructure/#infrastructure","text":"Coming soon! This section will contain guides and tutorials about infrastructure management and cloud services.","title":"Infrastructure"},{"location":"documentation/linux/","text":"Linux Administration \u00b6 Coming soon! This section will contain guides and tutorials about Linux system administration and best practices.","title":"Linux Administration"},{"location":"documentation/linux/#linux-administration","text":"Coming soon! This section will contain guides and tutorials about Linux system administration and best practices.","title":"Linux Administration"},{"location":"documentation/miscellaneous/","text":"Miscellaneous \u00b6 Coming soon! This section will contain various other DevOps-related guides and tutorials that don't fit into other categories.","title":"Overview"},{"location":"documentation/miscellaneous/#miscellaneous","text":"Coming soon! This section will contain various other DevOps-related guides and tutorials that don't fit into other categories.","title":"Miscellaneous"},{"location":"documentation/networking/","text":"Networking \u00b6 Coming soon! This section will contain guides and tutorials about networking concepts and configurations.","title":"Overview"},{"location":"documentation/networking/#networking","text":"Coming soon! This section will contain guides and tutorials about networking concepts and configurations.","title":"Networking"},{"location":"documentation/selfhosting/","text":"Self-Hosting Guide \u00b6 Coming soon! This section will contain guides and tutorials about self-hosting various services and applications.","title":"Overview"},{"location":"documentation/selfhosting/#self-hosting-guide","text":"Coming soon! This section will contain guides and tutorials about self-hosting various services and applications.","title":"Self-Hosting Guide"}]}